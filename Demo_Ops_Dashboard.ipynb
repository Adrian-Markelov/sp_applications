{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6m1PNKiOrN9",
        "outputId": "419c6b59-5fb8-415b-e949-ae9adf7a0e43",
        "cellView": "form",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: dash in /usr/local/lib/python3.10/dist-packages (2.18.1)\n",
            "Requirement already satisfied: dash-bootstrap-components in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.1)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash) (3.0.4)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (5.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash) (2.32.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash) (71.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash) (3.0.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash) (3.20.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dash) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# @title Install Required Packages\n",
        "# !pip install --upgrade gspread google-auth google-auth-oauthlib google-auth-httplib2\n",
        "# !pip install --upgrade gspread gspread_dataframe oauth2client\n",
        "# !pip install ipywidgets\n",
        "\n",
        "!pip install plotly dash dash-bootstrap-components\n",
        "\n",
        "\n",
        "# Old libraries probably won't need...\n",
        "# !pip install jupyter-dash\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UewmlKaPO-sT",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Load Upcoming Batch Sheets {\"vertical-output\":true}\n",
        "upcoming_batch_sheets_url = \"https://docs.google.com/spreadsheets/d/1X8ZbxKMyjig_GIMc5DkYo5bHXx0etwuFSn8vDWkABZ8/edit?gid=1568041822#gid=1568041822\" # @param {\"type\":\"string\",\"placeholder\":\"https://docs.google.com/spreadsheets/d/1YUUrrueZ2KkFnS-pViEjt9uKET4CAalyZXJWmJhPWHI/edit\"}\n",
        "current_batch_column = \"2025 - 2026 [upcoming_batch]\" # @param {\"type\":\"string\"}\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.service_account import Credentials\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "from google.auth import default\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Authenticate and initialize the gspread client\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Open the Google Sheet\n",
        "upcoming_batch_spreadsheet = gc.open_by_url(upcoming_batch_sheets_url)\n",
        "\n",
        "# Select the first worksheet (tab) in the sheet\n",
        "upcoming_batch_worksheet1 = upcoming_batch_spreadsheet.get_worksheet(0)\n",
        "\n",
        "# Get all the values from the worksheet\n",
        "upcoming_batch_data1 = upcoming_batch_worksheet1.get_all_values()\n",
        "upcoming_batch_df1 = pd.DataFrame(upcoming_batch_data1[1:], columns=upcoming_batch_data1[0])\n",
        "\n",
        "# Select the second worksheet (tab) in the sheet\n",
        "upcoming_batch_worksheet2 = upcoming_batch_spreadsheet.get_worksheet(1)\n",
        "\n",
        "# Get all the values from the worksheet\n",
        "upcoming_batch_data2 = upcoming_batch_worksheet2.get_all_values()\n",
        "upcoming_batch_df2 = pd.DataFrame(upcoming_batch_data2[1:], columns=upcoming_batch_data2[0])\n",
        "\n",
        "# Remove overlapping columns from the first DataFrame\n",
        "# Except for the \"SP ID\" column (common key for joining)\n",
        "columns_to_replace = upcoming_batch_df2.columns.difference(['SP ID'])\n",
        "upcoming_batch_df1 = upcoming_batch_df1.drop(columns=columns_to_replace, errors='ignore')\n",
        "\n",
        "# Perform a left join on 'SP ID' and allow the second DataFrame to replace any overlapping columns\n",
        "upcoming_batch_df = pd.merge(upcoming_batch_df1, upcoming_batch_df2, on='SP ID', how='left')\n",
        "\n",
        "def clean_upcoming_batch_df(upcoming_batch_df):\n",
        "  upcoming_batch_df = upcoming_batch_df.replace(\"\", None)\n",
        "  upcoming_batch_df = upcoming_batch_df[pd.notna(upcoming_batch_df['Applied Date'])].copy()\n",
        "  upcoming_batch_df = upcoming_batch_df[upcoming_batch_df['Registration Batch'] == current_batch_column]\n",
        "  upcoming_batch_df = upcoming_batch_df.drop_duplicates(subset=['SP ID'], keep='first')\n",
        "  upcoming_batch_df = upcoming_batch_df.dropna(subset=['SP ID']).replace('', pd.NA).dropna(subset=['SP ID'])\n",
        "  upcoming_batch_df = upcoming_batch_df.sort_values(by='SP ID', key=lambda col: col.astype(int))\n",
        "  # Assign each applicant into a wait time bucket\n",
        "  # bin_edges = [-1, 1, 2, 3, 4, float('inf')]\n",
        "  # bin_labels = ['1', '2', '3', '4', '5+']\n",
        "  # upcoming_batch_df[\"Call Count Bucketed\"] = pd.cut(upcoming_batch_df['Call Count'].apply(lambda x: int(x)), bins=bin_edges, labels=bin_labels)\n",
        "  # upcoming_batch_df[\"Call Count Bucketed\"] = upcoming_batch_df[\"Call Count Bucketed\"].cat.add_categories('unknown')\n",
        "  # upcoming_batch_df[\"Call Count Bucketed\"] = upcoming_batch_df[\"Call Count Bucketed\"].fillna(\"unknown\")\n",
        "  return upcoming_batch_df\n",
        "\n",
        "upcoming_batch_df = clean_upcoming_batch_df(upcoming_batch_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpasPaU9fM7U",
        "outputId": "68426f71-be3c-442a-b8a3-c8e575fd0fe9",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sheet '2025-2026' already exists. Overwriting data...\n"
          ]
        }
      ],
      "source": [
        "# @title Write cleaned upcoming batch to prod and merge all prod clean batches\n",
        "\n",
        "prod_spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1i0mkuptt-YQFDfmt93EXQ1l5nurqUIYq6ArPfr_c8Ac/edit?gid=1070055378#gid=1070055378\"\n",
        "write_sheets = \"no\" # @param [\"yes\",\"no\"]\n",
        "\n",
        "prod_spreadsheet = gc.open_by_url(prod_spreadsheet_url)\n",
        "\n",
        "prod_upcoming_batch_sheet_name = \"2025-2026\"\n",
        "\n",
        "# Check if the sheet already exists\n",
        "try:\n",
        "    prod_upcoming_batch_worksheet = prod_spreadsheet.worksheet(prod_upcoming_batch_sheet_name)\n",
        "    print(f\"Sheet '{prod_upcoming_batch_sheet_name}' already exists. Overwriting data...\")\n",
        "\n",
        "    # Optional: Clear the existing data in the sheet (if required)\n",
        "    prod_upcoming_batch_worksheet.clear()\n",
        "\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    print(f\"Sheet '{prod_upcoming_batch_sheet_name}' does not exist. Creating a new sheet...\")\n",
        "    # Create a new worksheet\n",
        "    prod_upcoming_batch_worksheet = prod_spreadsheet.add_worksheet(title=prod_upcoming_batch_sheet_name, rows=f\"{upcoming_batch_df.shape[0]}\", cols=\"80\")\n",
        "\n",
        "if write_sheets == \"yes\":\n",
        "  # Write the DataFrame to the sheet (overwrite the data if the sheet exists)\n",
        "  set_with_dataframe(prod_upcoming_batch_worksheet, upcoming_batch_df)\n",
        "\n",
        "prod_batch_sheet_names_csv = \"2023-2024,2024-2025,2025-2026\" # @param {\"type\":\"string\",\"placeholder\":\"2023 - 2024, 2024 - 2025\"}\n",
        "\n",
        "\n",
        "# Get all previous batch worksheets\n",
        "prod_batch_sheet_names = prod_batch_sheet_names_csv.split(\",\")\n",
        "prod_batch_dfs = []\n",
        "for prod_batch_sheet_name in prod_batch_sheet_names:\n",
        "  prod_batch_worksheet = prod_spreadsheet.worksheet(prod_batch_sheet_name)\n",
        "  batch_data = prod_batch_worksheet.get_all_values()\n",
        "  prod_batch_dfs.append(pd.DataFrame(batch_data[1:], columns=batch_data[0]))\n",
        "\n",
        "all_batches_df = pd.concat(prod_batch_dfs)\n",
        "\n",
        "def clean_all_batches_df(all_batches_df):\n",
        "  all_batches_df = all_batches_df.replace(\"\", None)\n",
        "  all_batches_df = all_batches_df[pd.notna(all_batches_df['Applied Date'])].copy()\n",
        "  all_batches_df = all_batches_df.drop_duplicates(subset=['SP ID'], keep='first')\n",
        "  all_batches_df = all_batches_df.dropna(subset=['SP ID']).replace('', pd.NA).dropna(subset=['SP ID'])\n",
        "  all_batches_df = all_batches_df.sort_values(by='SP ID', key=lambda col: col.astype(int))\n",
        "  return all_batches_df\n",
        "\n",
        "all_batches_df = clean_all_batches_df(all_batches_df)\n",
        "\n",
        "prod_full_spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1SthvP1hLRNuwSNe0nDUxsE345GdmD0AOi_mNsYWijdo/edit?usp=sharing\"\n",
        "\n",
        "prod_full_spreadsheet = gc.open_by_url(prod_full_spreadsheet_url)\n",
        "\n",
        "prod_all_batches_sheet_name = \"full data cleaned\"\n",
        "# Get the all batches worksheet (note we expect it to exist already)\n",
        "prod_all_batches_worksheet = prod_full_spreadsheet.worksheet(prod_all_batches_sheet_name)\n",
        "if write_sheets == \"yes\":\n",
        "  set_with_dataframe(prod_all_batches_worksheet, all_batches_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtTLsPfghTZM"
      },
      "source": [
        "# *Generate Tables For Looker that are Indexed By Application Table's Columns*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3PWt1OOhAwC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Index Table By Columns with Count Stats\n",
        "\n",
        "column_stats_cols_csv_str = \"Applied Date,All Set Date,Full Profile Submission Date,Interview Done On,Final Approval Decision Datetime\" # @param {\"type\":\"string\",\"placeholder\":\"2023 - 2024, 2024 - 2025\"}\n",
        "column_stats_cols = column_stats_cols_csv_str.split(',')\n",
        "\n",
        "def create_columns_index(app_df, target_columns):\n",
        "  stats_dict = dict()\n",
        "  for col in target_columns:\n",
        "      stats_dict[col] = {\n",
        "          'Total Count': app_df[col].dropna().count(),\n",
        "      }\n",
        "  return stats_dict\n",
        "\n",
        "def create_columns_stats_df(all_batches_df, target_columns):\n",
        "  stats_dict = create_columns_index(all_batches_df, target_columns)\n",
        "  registration_batches = all_batches_df['Registration Batch'].unique().tolist()\n",
        "\n",
        "  for col in target_columns:\n",
        "    for batch in registration_batches:\n",
        "      stats_dict[col][batch + ' Count'] = all_batches_df[all_batches_df['Registration Batch'] == batch][col].count()\n",
        "      stats_dict[col][batch + ' Meditator Count'] = all_batches_df[(all_batches_df['Registration Batch'] == batch) & (all_batches_df['IE Status'] == 'Completed the program')][col].count()\n",
        "      stats_dict[col][batch + ' Non-Meditator Count'] = all_batches_df[(all_batches_df['Registration Batch'] == batch) & (all_batches_df['IE Status'] != 'Completed the program')][col].count()\n",
        "\n",
        "  stats_df = pd.DataFrame(stats_dict).T\n",
        "  stats_df = stats_df.reset_index().rename(columns={'index': 'Column Name'})\n",
        "  stats_df = stats_df.reset_index().rename(columns={'index': 'Index'})\n",
        "  return stats_df\n",
        "\n",
        "stats_df = create_columns_stats_df(all_batches_df, column_stats_cols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CisYFtW4hA32",
        "outputId": "b5df1069-64fa-4d8b-d851-227d0c5f9f22",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sheet 'App Field Stats' already exists. Overwriting data...\n"
          ]
        }
      ],
      "source": [
        "# @title Write Column Stats To Sheets\n",
        "write_sheets = \"no\" # @param [\"yes\",\"no\"]\n",
        "sheet_name = \"App Field Stats\"  # @param {\"type\":\"string\"}\n",
        "\n",
        "# Check if the sheet already exists\n",
        "try:\n",
        "    worksheet = prod_full_spreadsheet.worksheet(sheet_name)\n",
        "    print(f\"Sheet '{sheet_name}' already exists. Overwriting data...\")\n",
        "\n",
        "    # Optional: Clear the existing data in the sheet (if required)\n",
        "    worksheet.clear()\n",
        "\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    print(f\"Sheet '{sheet_name}' does not exist. Creating a new sheet...\")\n",
        "    # Create a new worksheet\n",
        "    worksheet = prod_full_spreadsheet.add_worksheet(title=sheet_name, rows=\"100\", cols=\"20\")\n",
        "\n",
        "if write_sheets == \"yes\":\n",
        "  # Write the DataFrame to the sheet (overwrite the data if the sheet exists)\n",
        "  set_with_dataframe(worksheet, stats_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pykVNz8sdDp4"
      },
      "source": [
        "# *Create Gui for Last Stage Wait Times Lookup Table*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cWN1JT1ZTlid",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Isolate Target Columns and Segment into Dated and Non Dated Columns\n",
        "\n",
        "target_column_names = [\n",
        "    'Pre-Reg Call Status',\n",
        "    'Pre-Registration Status',\n",
        "    'Pending Other Reason',\n",
        "    'Status of IE Interest',\n",
        "    'Is Starmarked?',\n",
        "    'Starmark Review',\n",
        "    'SDP Tagged - Status',\n",
        "    'Sdp Tagged Review Comments',\n",
        "    'Is IE Pending and All set?',\n",
        "    'All Set Date',\n",
        "    'Full profile form sent date',\n",
        "    'Profile Form Status',\n",
        "    'Full Profile Submission Date',\n",
        "    'Webinar Attended?',\n",
        "    'Webinar Reflection form filled?',\n",
        "    'Webinar Reflection form filled on',\n",
        "    'Interview Done On',\n",
        "    'Interview State',\n",
        "    'Previous Interview State',\n",
        "    'Interview Done By',\n",
        "    'Interviewer Opinion',\n",
        "    'Concerns',\n",
        "    'Interview Opinion On',\n",
        "    'Health Assessment Email Sent Date',\n",
        "    'Health Assessment Form Status',\n",
        "    'Health Assessment Submission Date',\n",
        "    'Doctor Approval Decision',\n",
        "    'Doctor Approval decision date',\n",
        "    'Ready For Review Date',\n",
        "    'Reviewer Decision',\n",
        "    'VRO/OCO Feedback Status',\n",
        "    'Review Decision On',\n",
        "    'Final Approval Decision Datetime',\n",
        "    'Final Approver Decision',\n",
        "    'Final Approval Form Status',\n",
        "    'Final Approval Email Send Datetime',\n",
        "    'Arrival Batch',\n",
        "    'Arrival Status',\n",
        "    'Onboarding Status',\n",
        "    'Onboarding Call Status',\n",
        "    'Are you coming as couple?',\n",
        "    'Are you Coming with Laptop?',\n",
        "    'Mode of Travel',\n",
        "    'Verification Status',\n",
        "    'VMS Checkin Status',\n",
        "    'SP Epass Status',\n",
        "    'Arrival Datetime',\n",
        "    'Cancellation Date',\n",
        "    'Cancellation Reason',\n",
        "    'Previous Status'\n",
        "    ]\n",
        "\n",
        "# Function to check if a column is a date column\n",
        "def is_date_column(series):\n",
        "  try:\n",
        "    series_nona = series.dropna()\n",
        "    if len(series_nona) == 0:\n",
        "      return False\n",
        "    # Try converting the entire series to datetime\n",
        "    pd.to_datetime(series_nona, format='%Y-%m-%d %H:%M:%S')\n",
        "    return True\n",
        "  except (ValueError, TypeError):\n",
        "    return False\n",
        "\n",
        "# Note that there will be some missing columns from both column sets if the series is empty.\n",
        "date_columns = [col for col in target_column_names if is_date_column(upcoming_batch_df[col]) and len(upcoming_batch_df[col].dropna()) != 0]\n",
        "date_columns = ['Applied Date'] + date_columns\n",
        "non_date_columns = [col for col in target_column_names if col not in date_columns and len(upcoming_batch_df[col].dropna()) != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQxYvNSVO-vr",
        "outputId": "5d868d9e-f6e0-43b9-f4bd-e5560f52b65b",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-7fc065a9c2bd>:63: FutureWarning:\n",
            "\n",
            "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Dated Stage Wait Counts Table\n",
        "\n",
        "date_columns_df = upcoming_batch_df[date_columns].copy()\n",
        "date_columns_df.index = upcoming_batch_df[\"SP ID\"].copy()\n",
        "# Convert all date string columns to pandas datetime types.\n",
        "for col in date_columns:\n",
        "    date_columns_df[col] = pd.to_datetime(date_columns_df[col], errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "if 'Doctor Approval decision date' in date_columns:\n",
        "    # Find the index\n",
        "    doctor_approval_index = date_columns.index('Doctor Approval decision date')\n",
        "else:\n",
        "    doctor_approval_index = -1\n",
        "\n",
        "# Insert 'Health Assessment Start Date' just before 'Doctor Approval decision date' in the date_columns list\n",
        "date_columns.insert(doctor_approval_index, 'Health Assessment Start Date')\n",
        "\n",
        "# Now, proceed with creating or adjusting 'Health Assessment Start Date' in the DataFrame (as you already did)\n",
        "date_columns_df['Health Assessment Start Date'] = date_columns_df.apply(\n",
        "    lambda row: max(row['Health Assessment Submission Date'], row['Ready For Review Date'])\n",
        "                if pd.notna(row['Health Assessment Submission Date']) else pd.NaT, axis=1\n",
        ")\n",
        "\n",
        "# Drop the original 'Health Assessment Submission Date' and 'Ready For Review Date' columns\n",
        "date_columns_df = date_columns_df.drop(columns=['Health Assessment Submission Date', 'Ready For Review Date','Review Decision On',])\n",
        "\n",
        "# Reorder the columns in the DataFrame to ensure 'Health Assessment Start Date' comes before 'Doctor Approval decision date'\n",
        "# Find the position of 'Doctor Approval decision date' in the columns of the DataFrame\n",
        "doctor_approval_index_df = date_columns_df.columns.get_loc('Doctor Approval decision date')\n",
        "\n",
        "# Reorder the columns in the DataFrame to ensure 'Health Assessment Start Date' is before 'Doctor Approval decision date'\n",
        "columns_reordered = list(date_columns_df.columns)\n",
        "columns_reordered.insert(doctor_approval_index_df, columns_reordered.pop(columns_reordered.index('Health Assessment Start Date')))\n",
        "\n",
        "# Assign the reordered columns back to the DataFrame\n",
        "date_columns_df = date_columns_df[columns_reordered]\n",
        "\n",
        "# Get the last stage reached by each user\n",
        "date_columns_df['Last Stage'] = date_columns_df.apply(lambda row: row.last_valid_index(), axis=1)\n",
        "\n",
        "# Get the timestamp of the last stage (useful for calculating Time Since Last Stage)\n",
        "date_columns_df['Last Timestamp'] = date_columns_df.apply(lambda row: row.dropna().iloc[-2], axis=1)\n",
        "\n",
        "# Define the current time (now)\n",
        "now = pd.Timestamp.now()\n",
        "\n",
        "# Calculate 'Time Since Last Stage' in days\n",
        "date_columns_df['Time Since Last Stage'] = (now - date_columns_df['Last Timestamp']).dt.days\n",
        "\n",
        "# Combine the 'Health Assessment Start Date' time difference with other stages\n",
        "# Update 'Time Since Last Stage' for rows where 'Last Stage' is 'Health Assessment Start Date'\n",
        "mask = date_columns_df['Last Stage'] == 'Health Assessment Start Date'\n",
        "date_columns_df.loc[mask, 'Time Since Last Stage'] = (now - date_columns_df['Health Assessment Start Date']).dt.days\n",
        "\n",
        "# Define bin edges and labels\n",
        "bin_edges = [-1, 10, 20, 30, 40, 50, float('inf')]\n",
        "bin_labels = ['0-10', '11-20', '21-30', '31-40', '41-50', '51+']\n",
        "\n",
        "# Assign each applicant into a wait time bucket based on the updated 'Time Since Last Stage'\n",
        "date_columns_df['Wait Time Bucket'] = pd.cut(date_columns_df['Time Since Last Stage'], bins=bin_edges, labels=bin_labels)\n",
        "\n",
        "# Create wait time distribution (histogram) across applicants per stage\n",
        "date_col_counts_df = date_columns_df.groupby(['Last Stage', 'Wait Time Bucket']).size().unstack(fill_value=0)\n",
        "\n",
        "# Reorder the index of stages to match the original order in 'date_columns'\n",
        "last_stages_ordered = [col for col in date_columns if col in set(date_col_counts_df.index.tolist())]\n",
        "date_col_counts_df = date_col_counts_df.reindex(last_stages_ordered)\n",
        "\n",
        "# Add Aggregate Stats columns for each stage\n",
        "last_dated_stage_counts_df = date_columns_df['Last Stage'].value_counts()\n",
        "avg_waiting_times_df = date_columns_df.groupby('Last Stage')['Time Since Last Stage'].mean().round(1)\n",
        "date_col_counts_df['Total Waiting Applicants'] = last_dated_stage_counts_df.copy()\n",
        "date_col_counts_df[\"Average Waiting Time\"] = avg_waiting_times_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xzAKuysidYE",
        "outputId": "0255186e-29fd-4d33-b87f-ec56d3ff77d1",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sheet 'Stage Wait Counts' already exists. Overwriting data...\n"
          ]
        }
      ],
      "source": [
        "# @title Write Dated Stage Wait Counts To Sheets\n",
        "wait_counts_sheet_name = \"Stage Wait Counts\" # @param {\"type\":\"string\"}\n",
        "\n",
        "# Check if the sheet already exists\n",
        "try:\n",
        "    worksheet = prod_full_spreadsheet.worksheet(wait_counts_sheet_name)\n",
        "    print(f\"Sheet '{wait_counts_sheet_name}' already exists. Overwriting data...\")\n",
        "\n",
        "    # Optional: Clear the existing data in the sheet (if required)\n",
        "    worksheet.clear()\n",
        "\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    print(f\"Sheet '{wait_counts_sheet_name}' does not exist. Creating a new sheet...\")\n",
        "    # Create a new worksheet\n",
        "    worksheet = prod_full_spreadsheet.add_worksheet(title=wait_counts_sheet_name, rows=\"100\", cols=\"20\")\n",
        "\n",
        "# Write the DataFrame to the sheet (overwrite the data if the sheet exists)\n",
        "set_with_dataframe(worksheet, date_col_counts_df.reset_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fRmRrfdfozw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title SP Status to Stage Mappings\n",
        "\n",
        "import io\n",
        "sp_status_mapping_df = pd.read_csv(io.StringIO('''\n",
        "SP Status,Column\n",
        "Pre-registration,Pre-Reg Call Status\n",
        "Pre-registration,Pre-Registration Status\n",
        "Pre-registration,Pending Other Reason\n",
        "Pre-registration,Status of IE Interest\n",
        "Pre-registration,Is Starmarked?\n",
        "Pre-registration,Starmark Review\n",
        "Pre-registration,SDP Tagged - Status\n",
        "Pre-registration,Sdp Tagged Review Comments\n",
        "Pre-registration,Is IE Pending and All set?\n",
        "Pre-registration,All Set Date\n",
        "Registration,Full profile form sent date\n",
        "Registration,Profile Form Status\n",
        "Registration,Full Profile Submission Date\n",
        "Registration,Webinar Attended?\n",
        "Registration,Webinar Reflection form filled?\n",
        "Registration,Webinar Reflection form filled on\n",
        "Interview,Interview Done On\n",
        "Interview,Interview State\n",
        "Interview,Previous Interview State\n",
        "Interview,Interview Done By\n",
        "Interview,Interviewer Opinion\n",
        "Interview,Concerns\n",
        "Interview,Interview Opinion On\n",
        "Health Assessment,Health Assessment Email Sent Date\n",
        "Health Assessment,Health Assessment Form Status\n",
        "Health Assessment,Health Assessment Submission Date\n",
        "Health Assessment,Doctor Approval Decision\n",
        "Health Assessment,Doctor Approval decision date\n",
        "Non Sadhaka Stage: Review Stage,Ready For Review Date\n",
        "Non Sadhaka Stage: Review Stage,Reviewer Decision\n",
        "Non Sadhaka Stage: Review Stage,VRO/OCO Feedback Status\n",
        "Non Sadhaka Stage: Review Stage,Review Decision On\n",
        "Non Sadhaka Stage: Final Approval,Final Approval Decision Datetime\n",
        "Non Sadhaka Stage: Final Approval,Final Approver Decision\n",
        "Non Sadhaka Stage: Final Approval,Final Approval Form Status\n",
        "Non Sadhaka Stage: Final Approval,Final Approval Email Send Datetime\n",
        "SP Status: Ready for Onboarding,Arrival Email Sent Date\n",
        "SP Status: Ready for Onboarding,Arrival Batch\n",
        "SP Status: Ready for Onboarding,Arrival Status\n",
        "SP Status: Ready for Onboarding,Onboarding Status\n",
        "SP Status: Ready for Onboarding,Onboarding Call Status\n",
        "SP Status: Ready for Onboarding,Are you coming as couple?\n",
        "SP Status: Ready for Onboarding,Are you Coming with Laptop?\n",
        "SP Status: Ready for Onboarding,Mode of Travel\n",
        "SP Status: Ready for Onboarding,Verification Status\n",
        "SP Status: Ready for Onboarding,VMS Checkin Status\n",
        "SP Status: Ready for Onboarding,SP Epass Status\n",
        "SP Status: Ready for Onboarding,Arrival Datetime\n",
        "SP Status: Cancelled,Cancellation Date\n",
        "SP Status: Cancelled,Cancellation Reason\n",
        "SP Status: Cancelled,Previous Status\n",
        "'''))\n",
        "stage_to_status_mapping = dict()\n",
        "status_to_stage_mapping = dict()\n",
        "for row in range(sp_status_mapping_df.shape[0]):\n",
        "  sp_status = sp_status_mapping_df['SP Status'].iloc[row]\n",
        "  column_name = sp_status_mapping_df['Column'].iloc[row]\n",
        "  if column_name in date_columns:\n",
        "    continue\n",
        "  stage_to_status_mapping[column_name] = sp_status\n",
        "  if sp_status not in status_to_stage_mapping.keys():\n",
        "    status_to_stage_mapping[sp_status] = [column_name]\n",
        "  else:\n",
        "    status_to_stage_mapping[sp_status].append(column_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnF1xn4hFZWu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Stage - Substage Counts Table\n",
        "\n",
        "stage_counts_dfs = []\n",
        "for stage in non_date_columns:\n",
        "  stage_counts_df = upcoming_batch_df[['SP ID'] + non_date_columns].groupby(stage, observed=False).size().reset_index().rename(columns={stage: 'Substage', 0: 'count'})\n",
        "  stage_counts_df.insert(0,'Stage', stage)\n",
        "  stage_counts_df.insert(0, 'SP Status',  stage_to_status_mapping[stage])\n",
        "  stage_counts_dfs.append(stage_counts_df)\n",
        "stage_counts_df = pd.concat(stage_counts_dfs).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEE06NfWBBbF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Status Tags Table\n",
        "\n",
        "# 'Arrival Tags' missing from target columns\n",
        "status_tags = ['Application Tags','Pre Registration Tags', 'Registration Tags', 'Interview Tags', 'Arrival Tags']\n",
        "status_tags_df = pd.DataFrame()\n",
        "status_tags_df = pd.DataFrame(columns=['Status Tag', 'Tag State', 'Count'])\n",
        "for status_tag in status_tags:\n",
        "  count_col_name = status_tag + \" tag count\"\n",
        "  status_tag_df = upcoming_batch_df[['SP ID', status_tag]].groupby(status_tag).size().reset_index().rename(columns={ status_tag: 'Tag State', 0: 'Count'})\n",
        "  status_tag_df.insert(0, 'Status Tag', status_tag)\n",
        "  status_tags_df = pd.concat([status_tags_df, status_tag_df])\n",
        "status_tags_df = status_tags_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "liCdv18dPCNM",
        "outputId": "8112a255-432e-46fe-bb8c-a46d7bc19e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash app running on:\n",
            "\u001b[31mWarning: This function may stop working due to changes in browser security.\n",
            "Try `serve_kernel_port_as_iframe` instead. \u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8050, \"/\", \"http://127.0.0.1:8050/\", window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Generate Dynamic Dashboard for getting Stage, SubStage and Subsubstage Counts and User Id's\n",
        "\n",
        "import dash\n",
        "from dash import Dash, dash_table, html, dcc, Input, Output\n",
        "\n",
        "\n",
        "app = dash.Dash(__name__)\n",
        "# app = JupyterDash(__name__)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# ------------- HTML LAYOUT AND SPECS FOR DASHBOARDS ---------------------------\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Dashboard Overview HTML\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "num_cancelations = upcoming_batch_df[pd.notna(upcoming_batch_df['Cancellation Date'])]['Cancellation Date'].shape[0]\n",
        "num_completed_apps = upcoming_batch_df[pd.notna(upcoming_batch_df['Final Approval Email Send Datetime'])]['Final Approval Email Send Datetime'].shape[0]\n",
        "num_apps = upcoming_batch_df.shape[0]\n",
        "\n",
        "scorecard_style={\n",
        "        \"border\": \"1px solid #ddd\",\n",
        "        \"border-radius\": \"8px\",\n",
        "        \"padding\": \"20px\",\n",
        "        \"width\": \"200px\",     # Fixed width\n",
        "        \"height\": \"150px\",    # Fixed height\n",
        "        \"textAlign\": \"center\",\n",
        "        \"box-shadow\": \"2px 2px 12px rgba(0,0,0,0.1)\",\n",
        "        \"display\": \"flex\",\n",
        "        \"flex-direction\": \"column\",\n",
        "        \"justify-content\": \"center\",  # Center content vertically\n",
        "        \"align-items\": \"center\",      # Center content horizontally\n",
        "    }\n",
        "\n",
        "data_updated_until_scorecard = html.Div(\n",
        "    children=[\n",
        "        html.H4(\"Last Updated On\", style={\"margin-bottom\": \"10px\", \"margin-top\": \"0px\", 'fontSize': '18px'}),\n",
        "        html.H5(f\"{date_columns_df['Applied Date'].max().date()}\", style={\"margin\": \"0px\", 'fontWeight': 'bold', 'fontSize': '32px'}),\n",
        "    ],\n",
        "    style=scorecard_style\n",
        ")\n",
        "\n",
        "total_upcoming_apps_scorecard = html.Div(\n",
        "    children=[\n",
        "        html.H4(\"Total Applicants\", style={\"margin-bottom\": \"10px\", \"margin-top\": \"0px\", 'fontSize': '18px'}),\n",
        "        html.H5(f\"{upcoming_batch_df['SP ID'].unique().shape[0]}\", style={\"margin\": \"0px\", 'fontWeight': 'bold', 'fontSize': '32px'}),\n",
        "    ],\n",
        "    style=scorecard_style\n",
        ")\n",
        "\n",
        "waiting_count_scorecard = html.Div(\n",
        "    children=[\n",
        "        html.H4(\"Not Approved Applicants\", style={\"margin-bottom\": \"10px\", \"margin-top\": \"0px\", 'fontSize': '18px'}),\n",
        "        html.H5(f\"{num_apps - num_completed_apps - num_cancelations}\", style={\"margin\": \"0px\", 'fontWeight': 'bold', 'fontSize': '32px'}),\n",
        "    ],\n",
        "    style=scorecard_style\n",
        ")\n",
        "\n",
        "cancellation_count_scorecard = html.Div(\n",
        "    children=[\n",
        "        html.H4(\"Cancelled Applicants\", style={\"margin-bottom\": \"10px\", \"margin-top\": \"0px\", 'fontSize': '18px'}),\n",
        "        html.H5(f\"{num_cancelations}\", style={\"margin\": \"0px\", 'fontWeight': 'bold', 'fontSize': '32px'}),\n",
        "    ],\n",
        "    style=scorecard_style\n",
        ")\n",
        "\n",
        "completed_count_scorecard = html.Div(\n",
        "    children=[\n",
        "        html.H4(\"Approval Email Sent\", style={\"margin-bottom\": \"10px\", \"margin-top\": \"0px\", 'fontSize': '18px'}),\n",
        "        html.H5(f\"{num_completed_apps}\", style={\"margin\": \"0px\", 'fontWeight': 'bold', 'fontSize': '32px'}),\n",
        "    ],\n",
        "    style=scorecard_style\n",
        ")\n",
        "\n",
        "dashboard_overview_html = [\n",
        "    html.H1('Application Operations Dashboard'),\n",
        "    html.Div(\n",
        "            [\n",
        "                data_updated_until_scorecard,\n",
        "                total_upcoming_apps_scorecard,\n",
        "                waiting_count_scorecard,\n",
        "                cancellation_count_scorecard,\n",
        "                completed_count_scorecard\n",
        "            ],\n",
        "            style={\n",
        "                'display': 'flex',\n",
        "                'justify-content': 'center',  # Centers scorecards horizontally\n",
        "                'align-items': 'center',      # Aligns the scorecards vertically\n",
        "                'gap': '20px',                # Space between scorecards\n",
        "            }\n",
        "        )\n",
        "]\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Status Tags Table HTML\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "status_tags_html = [\n",
        "    html.H1('SP Tags Counts'),\n",
        "    dash_table.DataTable(\n",
        "        id='status_tags_heatmap',\n",
        "        columns=[{\"name\": i, \"id\": i} for i in status_tags_df.columns],\n",
        "        data=status_tags_df.reset_index().to_dict('records'),\n",
        "        style_data_conditional=[{\n",
        "            'if': {'row_index': 'odd'},\n",
        "            'backgroundColor': 'rgb(248, 248, 248)'\n",
        "        }],\n",
        "        style_header={\n",
        "            'backgroundColor': 'rgb(230, 230, 230)',\n",
        "            'fontWeight': 'bold'\n",
        "        },\n",
        "        style_cell={'textAlign': 'center'},\n",
        "        cell_selectable=True,\n",
        "    ),\n",
        "    html.Div(id='status_tags_user_ids'),\n",
        "]\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Dated Stages Table HTML\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "dated_stages_table_description = \"\"\"\n",
        "The table below shows the number of applicants in each cell which are currently\n",
        "waiting in the cells corresponding \"Last Stage\" row and \"Wait Time\" bucket in days.\n",
        "Ex. Last Stage: \"Applied Date\" and Wait Time: \"1-10\" days since applicant applied and\n",
        "has yet to move to the next stage of the application process. You can click on\n",
        "the cell to get the list of applicant SP ID's for that stage and wait time. You\n",
        "can also filter down those applicants with the drop down menus by first choosing\n",
        "what Substage They are in of the currently selected stage and what Subsubstage\n",
        "they are in of the now selected Substage.\n",
        "\"\"\"\n",
        "dated_stages_html = [\n",
        "    html.H1('Application Wait Times'),\n",
        "    html.P(dated_stages_table_description),\n",
        "    dash_table.DataTable(\n",
        "        id='dated_stages_heatmap',\n",
        "        columns=[{\"name\": i, \"id\": i} for i in date_col_counts_df.columns.insert(0, 'Last Stage')],\n",
        "        data=date_col_counts_df.reset_index().to_dict('records'),\n",
        "        style_data_conditional=[{\n",
        "            'if': {'row_index': 'odd'},\n",
        "            'backgroundColor': 'rgb(248, 248, 248)'\n",
        "        }],\n",
        "        style_header={\n",
        "            'backgroundColor': 'rgb(230, 230, 230)',\n",
        "            'fontWeight': 'bold'\n",
        "        },\n",
        "        style_cell={'textAlign': 'center'},\n",
        "        cell_selectable=True,\n",
        "    ),\n",
        "    html.Div(id='user_ids'),\n",
        "]\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Stage and Substage Table HTML\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "stage_substage_table_description = \"\"\"\n",
        "Select a row in the table below of the Stage Substage pair you would like to\n",
        "get the SP ID's for. Use the two drop down menus to shrink the table to the\n",
        "desired SP Status and Stage columns that should be available. You can deselect\n",
        "both to get the full table of all Stage - Substage pairs (note this is a very\n",
        "large table.)\n",
        "\"\"\"\n",
        "\n",
        "sp_status_dropdown_options = [\n",
        "    {'label': status, 'value': status} for status in status_to_stage_mapping.keys()\n",
        "]\n",
        "\n",
        "stages_default_options = [{'label': stage, 'value': stage} for stage in status_to_stage_mapping['Pre-registration']]\n",
        "substage_table_html = [\n",
        "    html.H1('Stage and Substage'),\n",
        "    html.P(stage_substage_table_description),\n",
        "    dcc.Dropdown(id='sp_status_dropdown', options=sp_status_dropdown_options, value='Pre-registration'),\n",
        "    dcc.Dropdown(id='stage_dropdown', options=stages_default_options, value='Pre-Reg Call Status'),\n",
        "    dash_table.DataTable(\n",
        "        id='substage_heatmap',\n",
        "        columns=[{\"name\": i, \"id\": i} for i in stage_counts_df.columns],\n",
        "        data=stage_counts_df.reset_index().to_dict('records'),\n",
        "        style_data_conditional=[{\n",
        "            'if': {'row_index': 'odd'},\n",
        "            'backgroundColor': 'rgb(248, 248, 248)'\n",
        "        }],\n",
        "        style_header={\n",
        "            'backgroundColor': 'rgb(230, 230, 230)',\n",
        "            'fontWeight': 'bold'\n",
        "        },\n",
        "        style_cell={'textAlign': 'center'},\n",
        "        cell_selectable=True,\n",
        "    ),\n",
        "    html.Div(id='substage_user_ids'),\n",
        "]\n",
        "\n",
        "# Combine HTML modules into a single layout\n",
        "app.layout = html.Div(dashboard_overview_html + substage_table_html +\n",
        "                      status_tags_html + dated_stages_html)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# ------------------------------------------------------------------------------\n",
        "# ------------- DASHBOARD FEATURE CALL BACK FUNCTIONS --------------------------\n",
        "# ------------------------------------------------------------------------------\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Stage and Substage Table Callbacks and utils\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "@app.callback(\n",
        "    Output('stage_dropdown', 'options'),\n",
        "    [Input('sp_status_dropdown', 'value')]\n",
        ")\n",
        "def update_dropdown(sp_status_selected):\n",
        "  if sp_status_selected:\n",
        "    stages = status_to_stage_mapping[sp_status_selected]\n",
        "    return [{'label': stage, 'value': stage} for stage in stages]\n",
        "\n",
        "  else:\n",
        "    return [{'label': 'nothing', 'value': 'nothing'}]\n",
        "\n",
        "@app.callback(\n",
        "    Output('substage_heatmap', 'data'),\n",
        "    [Input('sp_status_dropdown', 'value'),\n",
        "     Input('stage_dropdown', 'value')]\n",
        ")\n",
        "def update_dropdown(sp_status_selected, stage):\n",
        "  if sp_status_selected and stage:\n",
        "    return stage_counts_df[(stage_counts_df['SP Status']==sp_status_selected) & (stage_counts_df['Stage']==stage)].reset_index().to_dict('records')\n",
        "  else:\n",
        "    return stage_counts_df.reset_index().to_dict('records')\n",
        "\n",
        "@app.callback(\n",
        "    Output('substage_user_ids', 'children'),\n",
        "    [Input('substage_heatmap', 'active_cell'),\n",
        "     Input('sp_status_dropdown', 'value'),\n",
        "     Input('stage_dropdown', 'value')]\n",
        ")\n",
        "def display_substage_user_ids(active_cell, sp_status, stage):\n",
        "    if active_cell and sp_status and stage:\n",
        "        substage = stage_counts_df[(stage_counts_df['SP Status']==sp_status) & (stage_counts_df['Stage']==stage)]['Substage'].reset_index(drop=True).iloc[active_cell['row']]\n",
        "        selected_users = upcoming_batch_df[upcoming_batch_df[stage]==substage]['SP ID'].unique()\n",
        "        selected_users_str = ','.join(selected_users)\n",
        "        return html.Pre(f\"User IDs in {stage} - {substage}:\\n{selected_users_str}\")\n",
        "    elif active_cell:\n",
        "      stage = stage_counts_df['Stage'].iloc[active_cell['row']]\n",
        "      substage = stage_counts_df['Substage'].iloc[active_cell['row']]\n",
        "      selected_users = upcoming_batch_df[upcoming_batch_df[stage]==substage]['SP ID'].unique()\n",
        "      selected_users_str = ','.join(selected_users)\n",
        "      return html.Pre(f\"\\nUser IDs in {stage} - {substage}:\\n{selected_users_str}\")\n",
        "    return \"\\nClick on a cell to see the user IDs.\"\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Status Tags Callbacks and utils\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Callback to output user ids based on clicked cell\n",
        "@app.callback(\n",
        "    Output('status_tags_user_ids', 'children'),\n",
        "    [Input('status_tags_heatmap', 'active_cell')]\n",
        ")\n",
        "def display_status_tags_user_ids(active_cell):\n",
        "    if active_cell:\n",
        "        row = active_cell['row']\n",
        "        status_tag = status_tags_df['Status Tag'].iloc[row]\n",
        "        tag_state = status_tags_df['Tag State'].iloc[row]\n",
        "        selected_users = upcoming_batch_df['SP ID'][upcoming_batch_df[status_tag]==tag_state].unique()\n",
        "        selected_users_str = ','.join(selected_users)\n",
        "        return html.Pre(f\"User IDs in {status_tag} - {tag_state}:\\n{selected_users_str}\")\n",
        "\n",
        "    return \"Click on a cell to see the user IDs.\"\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Dated Stages Table Callbacks and utils\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Callback to output user ids based on clicked cell\n",
        "@app.callback(\n",
        "    Output('user_ids', 'children'),\n",
        "    [Input('dated_stages_heatmap', 'active_cell')]\n",
        ")\n",
        "def display_user_ids(active_cell):\n",
        "    if active_cell:\n",
        "        stage = date_col_counts_df.index[active_cell['row']]\n",
        "        wait_bin = date_col_counts_df.columns[active_cell['column'] - 1]\n",
        "        selected_users = date_columns_df[(date_columns_df['Last Stage'] == stage) & (date_columns_df['Wait Time Bucket'] == wait_bin)].index.tolist()\n",
        "        selected_users_str = ','.join(map(str, selected_users))\n",
        "        return html.Pre(f\"User IDs in {stage} {wait_bin}:\\n{selected_users_str}\")\n",
        "    return \"Click on a cell to see the user IDs.\"\n",
        "\n",
        "\n",
        "# There are three options right now for generating the dashboard html\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Option 1: Dash jupyter mode\n",
        "# This will create a localhost link and has suspect support from Colab due to\n",
        "# security features that may change\n",
        "# ----------------------------------------------------\n",
        "app.run(jupyter_mode=\"external\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Option 2: Link framing this juptyer cells frame?\n",
        "# ----------------------------------------------------\n",
        "# def get_colab_link(port):\n",
        "#     from google.colab.output import eval_js\n",
        "#     return eval_js(f\"google.colab.kernel.proxyPort({port})\")\n",
        "# # Display the public URL generated by Colab\n",
        "# print(f'Dashboard should be accessible at this URL: {get_colab_link(8050)}')\n",
        "# # Run the Dash app on port 8050\n",
        "# app.run_server(port=8050, debug=False, use_reloader=False)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Option 3: Run from JupyterDash\n",
        "# This might be deprecated in the future though\n",
        "# ----------------------------------------------------\n",
        "# note need to change: app = JupyterDash(__name__)\n",
        "# and add: from jupyter_dash import JupyterDash\n",
        "# app.run_server(mode='external')\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Option 4: Run locally in colab displaying in the console below\n",
        "# ----------------------------------------------------\n",
        "# Run Locally in Colab cell\n",
        "#app.run_server(debug=False)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Option 5: Run locally in colab displaying in the console below\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Option 6: Run on a third party service like ngrok\n",
        "# ----------------------------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ImcjN_FltNF_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}